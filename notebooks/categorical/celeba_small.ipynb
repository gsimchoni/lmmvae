{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmvae.dim_reduction_images import run_dim_reduction_images\n",
    "from lmmvae.simulation import Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv('../../data/celeba_small.csv')\n",
    "\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def read_image(img_file, height=72, width=60):\n",
    "    img = Image.open(img_file)\n",
    "    img = img.resize((width, height))\n",
    "    img = np.asarray(img, dtype=np.float32) / 255.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "img_path = '../../data/img_align_celeba_png/'\n",
    "for img_file in images_df['img_file']:\n",
    "    # images.append(plt.imread(img_path + img_file))\n",
    "    images.append(read_image(img_path +  img_file))\n",
    "\n",
    "X = np.array(images)\n",
    "\n",
    "RE_cols = ['celeb']\n",
    "Z = images_df[RE_cols].values\n",
    "\n",
    "print(X.shape) # (10000, 72, 60, 3)\n",
    "print(Z.shape) # (10000, 1)\n",
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "asizeof.asizeof(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cats_celebs = len(images_df['celeb'].unique())\n",
    "print(f'no. of sources: {n_cats_celebs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for LMMVAE and other methods, some unnecessary for current use-case therefore are none\n",
    "img_height, img_width, channels = X.shape[1:]\n",
    "mode = 'categorical'\n",
    "n_sig2bs = 1\n",
    "n_sig2bs_spatial = 0\n",
    "n_neurons = [32, 16]\n",
    "dropout = None\n",
    "activation = 'relu'\n",
    "RE_cols_prefix = 'z'\n",
    "thresh = None\n",
    "epochs = 200\n",
    "qs = [n_cats_celebs]\n",
    "q_spatial = None\n",
    "batch_size = 1000\n",
    "patience = None\n",
    "kernel_root = None\n",
    "U = None\n",
    "B_list = None\n",
    "est_cors = []\n",
    "n_neurons_re = n_neurons\n",
    "pred_unknown_clusters = False\n",
    "max_spatial_locs = 100\n",
    "time2measure_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['d', 'beta', 're_prior', 'experiment', 'exp_type', 'mse_X', 'sigma_b0_est', 'n_epoch', 'time',\n",
    "    'total_loss_tr', 'recon_loss_tr', 'kl_loss_tr', 're_kl_loss_tr', 'total_loss_te', 'recon_loss_te', 'kl_loss_te', 're_kl_loss_te'\n",
    "    ])\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=40)\n",
    "counter = Count().gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_reg_types(X_train, X_test, Z_train, Z_test, counter, d, beta, re_prior, i, verbose):\n",
    "    mse_lmmvae, sigmas, _, n_epochs_lmmvae, time_lmmvae, losses_lmmvae = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "            img_height, img_width, channels, d, 'lmmvae-cnn',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "    print('   finished lmmvae-cnn, mse: %.3f' % mse_lmmvae)\n",
    "    mse_ig, _, _, n_epochs_ig, time_ig, losses_ig = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "            img_height, img_width, channels, d, 'pca-ignore',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "    print('   finished pca-ignore, mse: %.3f' % mse_ig)\n",
    "    mse_ohe, _, _, n_epochs_ohe, time_ohe, losses_ohe = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "            img_height, img_width, channels, d, 'pca-ohe',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "    print('   finished pca-ohe, mse: %.3f' % mse_ohe)\n",
    "    mse_vaeig, _, _, n_epochs_vaeig, time_vaeig, losses_vaeig = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "            img_height, img_width, channels, d, 'vae-ignore',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "    print('   finished vae-ignore-cnn, mse: %.3f' % mse_vaeig)\n",
    "    mse_vaeem, _, _, n_epochs_vaeem, time_vaeem, losses_vaeem = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "            img_height, img_width, channels, d, 'vae-embed',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "    print('   finished vae-embed, mse: %.3f' % mse_vaeem)\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'lmmvae', mse_lmmvae, sigmas[1][0], n_epochs_lmmvae, time_lmmvae] + losses_lmmvae\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'pca-ignore', mse_ig, np.nan, n_epochs_ig, time_ig] + losses_ig\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'pca-ohe', mse_ohe, np.nan, n_epochs_ohe, time_ohe] + losses_ohe\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'vae-ignore', mse_vaeig, np.nan, n_epochs_vaeig, time_vaeig] + losses_vaeig\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'vae-embed', mse_vaeem, np.nan, n_epochs_vaeem, time_vaeem] + losses_vaeem\n",
    "    res.to_csv('res_celeba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [0.01]\n",
    "ds = [100, 200, 500]\n",
    "re_priors = [0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in betas:\n",
    "  for d in ds:\n",
    "    for re_prior in re_priors:\n",
    "      print(f'beta: {beta}, d: {d}, re_prior: {re_prior}:')\n",
    "      for i, (train_samp_subj, test_samp_subj) in enumerate(kf.split(range(n_cats_celebs))):\n",
    "        print('  iteration %d' % i)\n",
    "        train_index = images_df[images_df['celeb'].isin(train_samp_subj)].index.values\n",
    "        test_index = images_df[images_df['celeb'].isin(test_samp_subj)].index.values\n",
    "        X_train, X_test, Z_train, Z_test = X[train_index].copy(), X[test_index].copy(), Z[train_index].copy(), Z[test_index].copy()\n",
    "        iterate_reg_types(X_train, X_test, Z_train, Z_test, counter, d, beta, re_prior, i, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58232888a71497b14c2600f41783e14bf8a4ed364d880e61f45b8308dbbef17d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
