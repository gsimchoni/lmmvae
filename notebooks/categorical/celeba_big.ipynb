{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lmmvae.dim_reduction_images import run_dim_reduction_images\n",
    "from lmmvae.simulation import Count\n",
    "from lmmvae.utils_images import get_generators, sample_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '../../data/img_align_celeba_png/'\n",
    "images_df = pd.read_csv('../../data/celeba_small.csv')\n",
    "\n",
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cats_celebs = len(images_df['celeb'].unique())\n",
    "print(f'no. of sources: {n_cats_celebs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for LMMVAE and other methods, some unnecessary for current use-case therefore are none\n",
    "img_height, img_width, channels = (72, 60, 3)\n",
    "img_file_col = 'img_file'\n",
    "RE_col = 'celeb'\n",
    "RE_inputs = [images_df[RE_col].values]\n",
    "mode = 'categorical'\n",
    "n_sig2bs = 1\n",
    "n_sig2bs_spatial = 0\n",
    "n_neurons = [32, 16]\n",
    "dropout = None\n",
    "activation = 'relu'\n",
    "RE_cols_prefix = 'z'\n",
    "thresh = None\n",
    "epochs = 200\n",
    "qs = [n_cats_celebs]\n",
    "q_spatial = None\n",
    "batch_size = 1000\n",
    "patience = None\n",
    "kernel_root = None\n",
    "U = None\n",
    "B_list = None\n",
    "est_cors = []\n",
    "n_neurons_re = n_neurons\n",
    "pred_unknown_clusters = False\n",
    "max_spatial_locs = 100\n",
    "time2measure_dict = None\n",
    "\n",
    "if pred_unknown_clusters:\n",
    "    filter_col = RE_col\n",
    "else:\n",
    "    filter_col = 'filter_col'\n",
    "    images_df[filter_col] = np.arange(images_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['d', 'beta', 're_prior', 'experiment', 'exp_type', 'mse_X', 'sigma_b0_est', 'n_epoch', 'time',\n",
    "    'total_loss_tr', 'recon_loss_tr', 'kl_loss_tr', 're_kl_loss_tr', 'total_loss_te', 'recon_loss_te', 'kl_loss_te', 're_kl_loss_te'\n",
    "    ])\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=40)\n",
    "counter = Count().gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_reg_types(train_generator, valid_generator, test_generator, train_RE_inputs, counter, d, beta, re_prior, i, verbose):\n",
    "    mse_lmmvae, sigmas, _, n_epochs_lmmvae, time_lmmvae, losses_lmmvae = run_dim_reduction_images(None, None, None, None,\n",
    "            img_height, img_width, channels, d, 'lmmvae-cnn-gen',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list,\n",
    "            train_generator=train_generator, valid_generator=valid_generator, test_generator=test_generator, train_RE_inputs=train_RE_inputs)\n",
    "    print('   finished lmmvae-cnn, mse: %.3f' % mse_lmmvae)\n",
    "    # mse_ig, _, _, n_epochs_ig, time_ig, losses_ig = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "    #         img_height, img_width, channels, d, 'pca-ignore',\n",
    "    #         thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "    #         activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "    # print('   finished pca-ignore, mse: %.3f' % mse_ig)\n",
    "#     mse_ohe, _, _, n_epochs_ohe, time_ohe, losses_ohe = run_dim_reduction_images(X_train, X_test, Z_train, Z_test,\n",
    "#             img_height, img_width, channels, d, 'pca-ohe',\n",
    "#             thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "#             activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list)\n",
    "#     print('   finished pca-ohe, mse: %.3f' % mse_ohe)\n",
    "    mse_vaeig, _, _, n_epochs_vaeig, time_vaeig, losses_vaeig = run_dim_reduction_images(None, None, None, None,\n",
    "            img_height, img_width, channels, d, 'vae-ignore-cnn-gen',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list,\n",
    "            train_generator=train_generator, valid_generator=valid_generator, test_generator=test_generator)\n",
    "    print('   finished vae-ignore, mse: %.3f' % mse_vaeig)\n",
    "    mse_vaeem, _, _, n_epochs_vaeem, time_vaeem, losses_vaeem = run_dim_reduction_images(None, None, None, None,\n",
    "            img_height, img_width, channels, d, 'vae-embed-cnn-gen',\n",
    "            thresh, epochs, qs, q_spatial, n_sig2bs, n_sig2bs_spatial, est_cors, batch_size, patience, n_neurons, n_neurons_re, dropout,\n",
    "            activation, mode, beta, re_prior, kernel_root, pred_unknown_clusters, max_spatial_locs, time2measure_dict, verbose, U, B_list,\n",
    "            train_generator=train_generator, valid_generator=valid_generator, test_generator=test_generator)\n",
    "    print('   finished vae-embed, mse: %.3f' % mse_vaeem)\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'lmmvae', mse_lmmvae, sigmas[1][0], n_epochs_lmmvae, time_lmmvae] + losses_lmmvae\n",
    "    # res.loc[next(counter)] = [d, beta, re_prior, i, 'pca-ignore', mse_ig, np.nan, n_epochs_ig, time_ig] + losses_ig\n",
    "#     res.loc[next(counter)] = [d, beta, re_prior, i, 'pca-ohe', mse_ohe, np.nan, n_epochs_ohe, time_ohe] + losses_ohe\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'vae-ignore', mse_vaeig, np.nan, n_epochs_vaeig, time_vaeig] + losses_vaeig\n",
    "    res.loc[next(counter)] = [d, beta, re_prior, i, 'vae-embed', mse_vaeem, np.nan, n_epochs_vaeem, time_vaeem] + losses_vaeem\n",
    "    res.to_csv('res_celeba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = [0.01]\n",
    "ds = [100, 200, 500]\n",
    "re_priors = [0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in betas:\n",
    "  for d in ds:\n",
    "    for re_prior in re_priors:\n",
    "      print(f'beta: {beta}, d: {d}, re_prior: {re_prior}:')\n",
    "      if pred_unknown_clusters:\n",
    "        for i, (train_samp_subj, test_samp_subj) in enumerate(kf.split(range(n_cats_celebs))):\n",
    "          print('  iteration %d' % i)\n",
    "          train_samp_subj, valid_samp_subj = sample_split(i, train_samp_subj)\n",
    "          train_generator, valid_generator, test_generator = get_generators(\n",
    "            images_df, images_dir, train_samp_subj, valid_samp_subj, test_samp_subj, batch_size,\n",
    "            img_file_col, RE_col, RE_col, img_height, img_width)\n",
    "          train_RE_table = [RE_input[images_df[RE_col].isin(train_samp_subj)] for RE_input in RE_inputs]\n",
    "          iterate_reg_types(train_generator, valid_generator, test_generator, train_RE_table,\n",
    "                            counter, d, beta, re_prior, i, verbose=True)\n",
    "      else:\n",
    "        for i, (train_index, test_index) in enumerate(kf.split(range(images_df.shape[0]))):\n",
    "          print('  iteration %d' % i)\n",
    "          train_index, valid_index = sample_split(i, train_index)\n",
    "          train_generator, valid_generator, test_generator = get_generators(\n",
    "            images_df, images_dir, train_index, valid_index, test_index, batch_size,\n",
    "            img_file_col, RE_col, filter_col, img_height, img_width)\n",
    "          train_RE_inputs = [RE_input[images_df.index.isin(train_index)] for RE_input in RE_inputs]\n",
    "          iterate_reg_types(train_generator, valid_generator, test_generator, train_RE_inputs,\n",
    "                            counter, d, beta, re_prior, i, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58232888a71497b14c2600f41783e14bf8a4ed364d880e61f45b8308dbbef17d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
